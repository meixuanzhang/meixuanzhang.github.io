---
layout: post
title: 读《Dropout A Simple Way to Prevent Neural Networks from Overfitting》
date:   2019-01-27
categories:  深度学习
---

# 摘要  

具有大量参数的深度神经网络是非常强大的机器学习系统。然而，过度拟合是这种网络中的严重问题。通过组合许多不同大型神经网络的预测结果来处理过度拟合，在测试时非常缓慢。   
Dropout是一种解决此问题的技术，其关键的想法是在训练时，随机删除神经网络的神经元（及其连接）。这可以防止神经元间过度协同(co-adapting)。在训练中，Dropout从指数级不同“稀疏”网络中采样，获得不同的网络结构。在测试时，使用缩放权重了的整个神经网络预测，其可近似为平均所有这些 “稀疏” 网络的预测的效果。这显着减少过度拟合，比起其他正则化方法有了重大改进。   
Dropout提高了神经网络在(视觉，语音识别，文档分类和计算生物学等)监督学习任务的表现。

# 

