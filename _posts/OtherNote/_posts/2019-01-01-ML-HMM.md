---
layout: post
title: 隐马尔可夫模型（Hidden Markov Model，HMM）
date:   2019-01-01
categories: 
---

# 隐马尔可夫模型概念

当需要计算可观测序列概率时，可以使用Markov Chain,但很多时候我们感兴趣的是隐藏状态，没办法直接观测,例如：句子语法标记，我们不能直接观测到每次词标记，需要从词序列推断出词的标记。把标记叫作隐藏状态，无法直接观察出来。词记作观测值。    
HMM通过隐藏状态和观测值，建立概率模型，描述了一个含有隐含未知参数的马尔可夫过程。

**Notation**  

$$Q$$:隐藏状态**集合**$${q_{1},q_{2}..,q_{N}}$$  

$$V$$:观测值**集合**$${v_{1},v_{2}..,v_{M}}$$   

$$O$$:观测值序列 $$(o_{1},..o_{t},o_{t+1}...)$$

$$I$$:隐藏状态序列$$(i_{1},..i_{t},i_{t+1}...)$$

$$A$$:从一个隐藏状态转到另一个隐藏状态的概率矩阵,维度N*N    

$$B$$:不同隐藏状态下不同测量值概率矩阵，维度是N*M  

$$\pi$$:初始化隐藏状态概率分布


$$A=[a_{ij}]_{N \ast N}$$   

其中$$a_{ij}=P(i_{t+1}=q_{j} \mid i_{t}=q_{i}), i=1,2,3,..N;j=1,2,..N$$    

表示从隐藏状态$$q_{i}$$(t时刻的状态)转到隐藏状态$$q_{j}$$(t+1时刻的状态),也表示在时刻t处于状态$$q_{i}$$的条件下时刻t+1转移到状态$$q_{j}$$的概率。   

$$B=[b_{j}(k)]_{N \ast M}$$

其中$$b_{j}(k)=P(o_{t}=v_{k} \mid i_{t}=q_{j}), k=1,2,3,..M;j=1,2,..N$$  

表示在时刻t处于状态$$q_{j}$$的条件下生成观测值$$v_{k}$$  

$$\pi_{i}=P(i_{1}=q_{i}),i=1,2,..N$$  

隐马尔可夫模型(HMM)由初始概率状态$$\pi$$、隐藏转移概率矩阵$$A$$和观测值概率矩阵$$B$$决定，$$\pi ,A$$决定隐藏状态序列，$$B$$决定观测值序列，$$A,B,\pi$$是隐马尔可夫模型的三要素，用三元符号表示$$\lambda=(A,B,\pi)$$。  

隐藏状态转移概率矩阵$$A$$与初始状态概率向量$$\pi$$确定了隐藏的马尔可夫链，生成不可观测的状态序列，观测值概率矩阵$$B$$确定了如何从隐藏状态生成观测值，与隐藏状态序列综合确定了如何产生观测值序列。

隐马尔可夫模型的两个基本假设：  
1、齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻t+1的隐藏状态依赖于t时刻的隐藏状态，与其他时刻的隐藏状态及观测值无关。  

$$P(i_{t+1} \mid i_{t},..i_{1},o_{t}..o_{1})=P(i_{t+1} \mid i_{t}), t=1,2,...T$$   

2、观测值独立性假设。即假设任意时刻的观测值只依赖于该时刻的马尔可夫链的隐藏状态，与其他观测值及隐藏状态无关。
 
$$P(o_{t} \mid i_{t},..i_{1},o_{t-1}..o_{1})=P(o_{t} \mid i_{t})$$   

# 观测值序列生成过程

输入：隐马尔可夫模型$$\lambda=(A,B,\pi)$$，观测序列长度T；  
输出：观测序列$$O=(o_{1},o_{2},...o_{T})$$    
1、按照初始状态分布$$\pi$$产生隐藏状态$$i_{1}$$  
2、令$$t=1$$  
3、按照隐藏状态$$i_{t}$$的观测概率分布$$b_{i_{t}}(k)$$生成观测$$o_{t}$$  
4、按照隐藏状态$$i_{t}$$的状态转移概率分布$$\{a_{i_{t}i_{t+1}}\}$$产生隐藏状态$$i_{t+1}$$    
5、令$$t=t+1:$$如果$$t<T$$,转步3；否则终止

# 隐马尔可夫模型的3种问题
1、概率计算问题。给定模型$$\lambda=(A,B,\pi)$$和观测序列$$O=(o_{1},o_{2},..,o_{T})$$，计算在模型$$\lambda$$下观测序列$$O$$出现的概率$$P(O ;\lambda)$$。   
2、学习问题。已知观测序列$$O=(o_{1},o_{2},...o_{T})$$,估计模型$$\lambda=(A,B,\pi)$$参数，使得在该模型下观测序列概率$$P(O \mid \lambda)$$最大，即使用极大似然估计的方法。  
3、预测问题（Decoding）。已知模型$$\lambda=(A,B,\pi)$$和观测序列$$O=(o_{1},o_{2},...o_{T})$$，求给定观测序列条件概率$$P(I \mid O)$$最大的状态序列。  

## 1、概率计算问题  

已知：模型$$\lambda=(A,B,\pi)$$和观测序列$$O=(o_{1},o_{2},...o_{T})$$   
计算：$$P(O ;\lambda)$$  

### 直接计算法  

$$
P(O ;\lambda)=\sum_{I}P(O,I;\lambda)\\
=\sum_{I}P(O \mid I;\lambda)P(I;\lambda)
$$   

状态序列$$I=(i_{1},i_{2},..i_{T})$$的概率是:  

$$P(I;\lambda)=\pi_{i_{1}} a_{i_{1}i_{2}}a_{i_{2}i_{3}}...a_{i_{T-1}i_{T}}$$


对于固定的状态序列$$I=(i_{1},i_{2},..i_{T})$$,观测序列$$O=(o_{1},o_{2},..o_{T})$$的概率是：  

$$P(O \mid I;\lambda)=b_{i_{1}}(o_{1})b_{i_{2}}(o_{2})..b_{i_{T}}(o_{T})$$

$$O,I$$联合概率是：  

$$P(O,I;\lambda)=\pi_{i_{1}} b_{i_{1}}(o_{1}) a_{i_{1}i_{2}} b_{i_{2}}(o_{2})....a_{i_{T-1}i_{T}} b_{i_{T}}(o_{T})$$  

观测序列$$O$$的概率是$$P(O ;\lambda)$$:   

$$P(O;\lambda)=\sum_{I}P(O \mid I;\lambda)P(I;\lambda)\\
=\sum_{i_{1},i_{2},..i_{T}} \pi_{i_{1}} b_{i_{1}}(o_{1}) a_{i_{1}i_{2}} b_{i_{2}}(o_{2})....a_{i_{T-1}i_{T}} b_{i_{T}}(o_{T})
$$  

### 前向算法  
定义到$$t$$时刻部分观测序列为$$o_{1},o_{2},...o_{t}$$且t时刻状态为$$q_{i}$$的概率为前向概率，记作：

$$a_{t}(i)=P(o_{1},o_{2},...o_{t},i_{t}=q_{i};\lambda)$$

1、初值  

$$a_{1}(i)=P(o_{1},q_{i};\lambda)=P(q_{i})P(o_{1} \mid q_{i} ;\lambda)=\pi_{i}b_{i}(o_{1}),i=1,2..N$$     

这里$$q_{i}$$i是值隐藏状态取值对应下标   

2、递推   

$$
a_{t+1}(i)=P(o_{1},o_{2},...o_{t},o_{t+1},i_{t+1}=q_{i};\lambda)\\
=[\sum_{j=1}^N P(o_{1},o_{2},...o_{t},i_{t}=q_{j};\lambda)P(i_{t+1}=q_{i} \mid i_{t}=q_{j};\lambda)]P(o_{t+1}\mid i_{t+1}=q_{i};\lambda)\\
=[\sum_{j=1}^N a_{t}(j)a_{ji}]b_{t}(o_{t+1}),i=1,2..N
$$   

3、终止   

$$
P(O;\lambda)=\sum_{i=1}^Na_{T}(i)\\
a_{T}(i)=P(o_{1},o_{2},...o_{T},i_{T}=q_{i};\lambda)\\
$$   

### 后向算法  
给定隐马尔可夫模型$$\lambda$$,定义时刻$$t$$状态为$$q_{i}$$的条件下，从$$t+1$$到$$T$$的部分观测序列为$$o_{t+1},o_{t+2},...o_{T}$$的概率为后向概率： 

$$\beta_{t}(i)=P(o_{t+1},o_{t+2},...o_{T} \mid i_{t}=q_{i};\lambda)$$  

1、$$T$$时刻$$\beta$$:   

$$\beta_{T}(i)=1,i=1,2,..,N$$  

2、对$$t=T-1,T-2,..1$$：  

$$
\beta_{t}(i)=P(o_{t+1},o_{t+2},...o_{T} \mid i_{t}=q_{i};\lambda)\\
=\sum_{j=1}^NP(o_{t+1},o_{t+2},...o_{T},i_{t+1}=q_{j}\mid i_{t}=q_{i};\lambda)\\
=\sum_{j=1}^N \frac{P(i_{t+1}=q_{j};\lambda)}{P(i_{t}=q_{i};\lambda)}\frac{P(o_{t+1},o_{t+2},...o_{T},i_{t}=q_{i},i_{t+1}=q_{j})}{P(i_{t+1}=q_{j};\lambda)}\\
=\sum_{j=1}^N \frac{P(i_{t+1}=q_{j};\lambda)}{P(i_{t}=q_{i};\lambda)}P(o_{t+1},o_{t+2},...o_{T},i_{t}=q_{i} \mid i_{t+1}=q_{j};\lambda)\\
=\sum_{j=1}^N \frac{1}{P(i_{t}=q_{i};\lambda)}P(i_{t+1}=q_{j};\lambda)P(i_{t}=q_{i}\mid i_{t+1}=q_{j};\lambda) P(o_{t+1},o_{t+2},...o_{T}\mid i_{t+1}=q_{j};\lambda)\\
=\sum_{j=1}^N\frac{1}{P(i_{t}=q_{i};\lambda)}P(i_{t}=q_{i},i_{t+1}=q_{j};\lambda)P(o_{t+1},o_{t+2},...o_{T}\mid i_{t+1}=q_{j};\lambda)\\
= \sum_{j=1}^N P(i_{t+1}=q_{j}\mid i_{t}=q_{i};\lambda)P(o_{t+1}\mid i_{t+1}=q_{j};\lambda)P(o_{t+2},...o_{T} \mid i_{t+1}=q_{j};\lambda)\\
=\sum_{j=1}^Na_{ij}b_{j}(o_{t+1})\beta_{t+1}(j),i=1,2,..N   
$$

3、计算$$P(O;\lambda)$$:   

$$\beta_{1}(i)=P(o_{2},...o_{T} \mid i_{1}=q_{i};\lambda)$$

$$
P(O;\lambda)=P(o_{1},o_{2},...o_{T};\lambda)\\
=\sum_{i=1}^NP(o_{1}o_{2},...o_{T},i_{1}=q_{i};\lambda)\\
=\sum_{i=1}^NP(i_{1}=q_{i})P(o_{1},o_{2},...o_{T} \mid i_{1}=q_{i};\lambda)\\
=\sum_{i=1}^NP(i_{1}=q_{i})P(o_{1}\mid i_{1}=q_{i})P(o_{2},...o_{T} \mid i_{1}=q_{i};\lambda)\\
=\sum_{i=1}^N\pi_{i}b_{i}(o_{1})\beta_{1}(i)
$$

**利用前向概率和后向概率的定义可以将观测序列概率$$P(O;\lambda)$$统一写成**：  

$$
P(O; \lambda)=P(o_{1},o_{2},...o_{t},o_{t+1},o_{t+2},...o_{T};\lambda)\\
=\sum_{i=1}^N\sum_{j=1}^NP(o_{1},o_{2},...o_{t},o_{t+1},o_{t+2},...o_{T},i_{t+1}=q_{j},i_{t}=q_{i};\lambda)\\
=\sum_{i=1}^N\sum_{j=1}^NP(o_{1},o_{2},...o_{t},o_{t+1},o_{t+2},...o_{T},i_{t+1}=q_{j}\mid i_{t}=q_{i};\lambda)P(i_{t}=q_{i};\lambda)\\

=\sum_{i=1}^N\sum_{j=1}^NP(o_{1},o_{2},...o_{t}\mid i_{t}=q_{i};\lambda)P(i_{t}=q_{i};\lambda)P(o_{t+1},o_{t+2},...o_{T},i_{t+1}=q_{j}\mid i_{t}=q_{i};\lambda)\\

=\sum_{i=1}^N\sum_{j=1}^NP(o_{1},o_{2},...o_{t},i_{t}=q_{i};\lambda)P(o_{t+1},o_{t+2},...o_{T},i_{t+1}=q_{j}\mid i_{t}=q_{i};\lambda)\\
=\sum_{i=1}^N\sum_{j=1}^NP(o_{1},o_{2},...o_{t},i_{t}=q_{i};\lambda)P(i_{t+1}=q_{j}\mid i_{t}=q_{i};\lambda)P(o_{t+1}\mid i_{t+1}=q_{j};\lambda)P(o_{t+2},...o_{T} \mid i_{t+1}=q_{j};\lambda)\\
=\sum_{i=1}^N\sum_{j=1}^Na_{t}(i)a_{ij}b_{j}(o_{t+1})\beta_{t+1}(j)\\
=\sum_{i=1}^Na_{t}(i)\beta_{t}(i),t=1,2,..T-1
$$  

## 2、学习问题  
### 监督学习
已知：有S个长度相同的观测序列和对应的状态序列$$\{(O_{1},I_{1}),(O_{2},I_{2})..(O_{S},I_{S})\}$$
求：模型参数$$\lambda$$
利用极大似然估计法估计隐马尔可夫模型的参数    

$$logP((O_{1},I_{1}),(O_{2},I_{2})..(O_{s},I_{s});\lambda)=\sum_{s=1}^SlogP(O_{s},I_{s};\lambda)
=log\prod_{s=1}^S[\pi_{i_{1}^{(s)}} b_{i_{1}^{(s)}}   (o_{1}^{(s)})\prod_{t=2}^T(a_{i_{t-1}^{(s)}i_{t}^{(s)}}  b_{i_{t}^{(s)}}(o_{t}^{(s)}))]\\
=\sum_{s=1}^S[log\pi_{i_{1}^{(s)}}+  \sum_{t=2}^T log a_{i_{t-1}^{(s)}i_{t}^{(s)}}+ \sum_{t=1}^T log b_{i_{t}^{(s)}}(o_{t}^{(s)})]
$$

因为$$\sum_{i=1}^N\pi_{i}=1,\sum_{j=1}^Na_{ij}=1,\sum_{k=1}^Mb_{j}(k)=1$$, 带有等约束条件的优化问题，使用拉格朗日乘子法，所以：  

$$
L=Q-\lambda_{\pi}(\sum_{i=1}^N\pi_{i}-1)-\sum_{i=1}^N \lambda_{A_{i}}(\sum_{j=1}^Na_{ij}-1)-\sum_{i=1}^N \lambda_{B_{j}}(\sum_{k=1}^Mb_{j}(k)-1)\\
$$

对模型参数$$\pi_{i},b_{j}(k),a_{ij}$$求导：  

$$
\pi_{i}=\frac{\sum_{s=1}^S I(i_{1}^{(s)}=i)}{S}\\
a_{ij}=\frac{\sum_{s=1}^\S \sum_{t=2}^T  I(i_{t-1}^{(s)}=i,i_{t}^{(s)}=j)}{\sum_{s=1}^\S \sum_{t=2}^T  I(i_{t-1}^{(s)}=i)}\\
b_{j}(k) = \frac{\sum_{s=1}^\S \sum_{t=1}^T  I(i_{t}^{(s)}=j,o_{t}^{(s)}=k)}{\sum_{s=1}^\S \sum_{t=1}^T I(i_{t}^{(s)}=j)}
$$

### 非监督学习EM算法：Baum-Welch  

 Baum-Welch algorithm (Baum, 1972), a special case of the Expectation-Maximization  
已知：有S个长度相同的观测序列$$O=\{O_{1},O_{2},..O_{S}\}$$  
未知：有S个长度相同的隐藏状态序列$$I=\{I_{1},I_{2}..I_{S}\}$$  
求：模型参数$$\lambda$$   



**明确隐变量，写出完全数据的对数似然函数**   

这是没有使用jesen不等式下的对数似然函数： 

$$Q=\sum_{I}logP(O,I;\lambda)P(I\mid O;\lambda^{(i)})$$

因为：  

$$
P(I, O;\lambda^{(i)})=P(I\mid O;\lambda^{(i)})P(O;\lambda^{(i)})\\
P(I\mid O;\lambda^{(i)}) \propto P(I, O;\lambda^{(i)}) \\
$$

$$\propto$$成正比符号，$$P(O;\lambda^{(i)})$$是常数。

所以：  

$$
\lambda^{(i+1) }=\mathop{\arg\max}_{\lambda} \sum\limits_{I}logP(O,I;\lambda)P(I\mid O;\lambda^{(i)})\\
=\mathop{\arg\max}_{\lambda} \sum\limits_{I}logP(O,I;\lambda)P(I,O;\lambda^{(i)})\\
Q=\sum\limits_{I}logP(O,I;\lambda)P(I,O;\lambda^{(i)})
$$  

**EM算法的E步，确定目标函数Q**  

$$
P(O,I;\lambda)=\prod_{s=1}^S[\pi_{i_{1}^{(s)}} b_{i_{1}^{(s)}}   (o_{1}^{(s)})\prod_{t=2}^T(a_{i_{t-1}^{(s)}i_{t}^{(s)}}  b_{i_{t}^{(s)}}(o_{t}^{(s)}))]\\
logP(O,I;\lambda)=\sum_{s=1}^S[log\pi_{i_{1}^{(s)}}+  \sum_{t=2}^T log a_{i_{t-1}^{(s)}i_{t}^{(s)}}+ \sum_{t=1}^T log b_{i_{t}^{(s)}}(o_{t}^{(s)})]\\

Q=\sum\limits_{I} \sum_{s=1}^S[log\pi_{i_{1}^{(s)}}P(I,O;\lambda^{(i)})+  \sum_{t=2}^T log a_{i_{t-1}i_{t}^{(s)}}P(I,O;\lambda^{(i)})+ \sum_{t=1}^T log b_{i_{t}}^{(s)}(o_{t}^{(s)})P(I,O;\lambda^{(i)})]
$$  

    

对$$\pi_{i},b_{j}(k),a_{ij}$$求导：  

因为$$\sum_{i=1}^N\pi_{i}=1,\sum_{j=1}^Na_{ij}=1,\sum_{k=1}^Mb_{j}(k)=1$$, 带有等约束条件的优化问题，使用拉格朗日乘子法，所以：  

$$
L=Q-\lambda_{\pi}(\sum_{i=1}^N\pi_{i}-1)-\sum_{i=1}^N \lambda_{A_{i}}(\sum_{j=1}^Na_{ij}-1)-\sum_{i=1}^N \lambda_{B_{j}}(\sum_{k=1}^Mb_{j}(k)-1)\\
$$

$$\lambda_{\pi},\lambda_{A_{i}},\lambda_{B_{j}}$$是拉格朗日系数

**确定EM算法的M步:极大化目标函数，求模型参数**

$$
\frac{dL}{\lambda_{\pi}}=-(\sum_{i=1}^N\pi_{i}-1)=0\\

\frac{dL}{d\pi_{i}}=\frac{d}{d\pi_{i}}(\sum\limits_{I} \sum_{s=1}^Slog\pi_{i_{1}^{(s)}}P(I,O;\lambda^{(i)}))-\lambda_{\pi}=0\\
=\frac{d}{d\pi_{i}}(\sum_{r=1}^N \sum_{s=1}^S  log\pi_{r}P(i_{1}^{(s)}=r,O;\lambda^{(i)}))-\lambda_{\pi}=0\\
=\sum_{s=1}^S \frac{P(i_{1}^{(s)}=r,O;\lambda^{(i)})}{\pi_{i}}-\lambda_{\pi}=0\\

\pi_{i}=\sum_{s=1}^S \frac{P(i_{1}^{(s)}=i,O;\lambda^{(i)})}{\lambda_{\pi}}
$$  

需要对$$\pi_{i}$$进行标准化：  

$$
\pi_{i}=\frac{\sum_{s=1}^S  P(i_{1}^{(s)}=i,O;\lambda^{(i)}) } {\sum_{r=1}^N\sum_{s=1}^S  P(i_{1}^{(s)}=r,O;\lambda^{(i)})}\\
=\frac{1}{D}P(i_{1}^{(s)}=i\mid O^{(s)};\lambda^{(i)})
$$

求导参考：[Derivation of Baum-Welch Algorithm for Hidden Markov Models](https://people.eecs.berkeley.edu/~stephentu/writeups/hmm-baum-welch-derivation.pdf)     

## 3、预测问题

### 近似算法  


在每个时刻 t 选择在该时刻最有可能出现的状态$$i_{t}^{\ast}$$,从而得到一个状态序列$$I^{\ast}=(i_{1}^{\ast},i_{2}^{\ast}...i_{T}^{\ast})$$，将它作为预测结果。优点是计算简单，缺点是不能保证预测状态序列整体是最有可能的状态序列（贪心算法），并且这种方法得到的状态序列有可能存在转移概率为0的相邻状态。

给定隐马尔可夫模型$$\lambda$$和观测序列$$O=(o_{1},o_{2}...o_{T})$$,在时刻t处于状态$$q_{i}$$的概率$$\gamma_{i}$$是：  


$$
\gamma_{t}(i)=\frac{ P(O,i_{t}=q_{i};\lambda)}{\sum_{j=1}^N P(O,i_{t}=q_{j};\lambda)}\\
=\frac{ P(o_{1},o_{2}...o_{T},i_{t}=q_{i};\lambda)}{\sum_{j=1}^N P(o_{1},o_{2}...o_{T},i_{t}=q_{j};\lambda)}
$$

$$
P(o_{1},o_{2}...o_{T},i_{t}=q_{i};\lambda) =\sum_{r=1}^N  P(o_{1},o_{2}...o_{T},i_{t+1}=q_{r} ,i_{t}=q_{i};\lambda)\\
=\sum_{r=1}^N a_{t}(i) a_{ir}b_{r}(o_{t+1})\beta_{t+1}(r)=a_{t}(i)beta_{t}(i)
$$

$$
\gamma_{t}(i)=\frac{ a_{t}(i)beta_{t}(j)}{\sum_{j=1}^N a_{t}(j)beta_{t}(j)}\\
$$

### 维特比算法  

$$
a_{ij}=\frac{\sum_{s=1}^S \sum_{t=2}^T   P(i_{t-1}^{(s)}=i,i_{t}^{(s)}=j \mid O^{(s)};\lambda^{(i)}) } {\sum_{s=1}^S \sum_{t=2}^T P(i_{t-1}^{(s)}=i\mid O^{(s)};\lambda^{(i)})}\\
b_{j}(k)=\frac{\sum_{s=1}^S \sum_{t=1}^T P(i_{t}^{(s)}=j\mid O^{(s)};\lambda^{(i)}) I(o_{t}^{(s)}=k)}{\sum_{s=1}^S \sum_{t=1}^T P(i_{t}^{(s)}=j\mid O^{(s)};\lambda^{(i)})}
$$  





参考：  
李航《统计学习》  
[Hidden Markov Models](https://web.stanford.edu/~jurafsky/slp3/A.pdf)  
[Derivation of Baum-Welch Algorithm for Hidden Markov Models](https://people.eecs.berkeley.edu/~stephentu/writeups/hmm-baum-welch-derivation.pdf)  
[Derivation of Baum-Welch Algorithm for Hidden Markov Models](https://people.eecs.berkeley.edu/~stephentu/writeups/hmm-baum-welch-derivation.pdf)  
