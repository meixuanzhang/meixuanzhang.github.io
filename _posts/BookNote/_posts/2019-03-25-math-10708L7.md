---
layout: post
title: 译Lecture 6 Maximum likelihood learning of undirected GM
date:   2019-03-25
categories: ["Probabilistic Graphical Models"]
---  

学习UGM的算法以及CRF的简要概述。

# Introduction and IPF(iterative proportional fitting)   

**MLE适用于无向图形模型**  

我们有一个无向图模型，并且我们知道使用Hammersley-Clifford定理可以用吉布斯分布表示它。现在的问题是,是否可以按照针对有向图模型的合理程序来找到UGM的最大似然期望(MLE)？ 答案是否定的-我们不能。 这是因为对于有向图模型，对数似然分解为项的总和，即每个项（节点，其父节点）。 但是，这不适用于无向图模型，因为存在归一化常数$$Z$$，该归一化常数是所有参数的函数，因此概率分布不会拆分为项的和。

$$
\begin{aligned}
P \left( x _ { 1 } , \ldots , x _ { n } \right) &amp; = \frac { 1 } { Z } \prod _ { c \in C } \psi _ { c } \left( \mathbf { x } _ { c } \right) \\
Z &amp; = \sum _ { x _ { 1 } , \ldots , x _ { n } } \prod _ { c \in C } \psi _ { c } \left( \mathbf { x } _ { c } \right)
\end{aligned}
$$

尽管这是一个很大的缺点，但是我们仍然使用无向图模型，因为它们很有用-它们用于表示某些特殊情况，这些特殊情况不能通过有向图模型来表示。 下一节概述了通过对数似然的导数查找MLE的过程以及由此产生的困难。

**关于UGMs的对数似然** 

在这里，我们介绍两个新的数量-总计数(Total Count)和集团数(Clique Count)。无向图形模型$$(V,E)$$的总计数就是在数据集中观察到结构x$$(X_{v}=x)$$

$$m ( \mathbf { x } ) = \sum _ { n } \delta \left( \mathbf { x } , \mathbf { x } _ { n } \right)$$

**迭代比例恰当(Iterative Proportional Fitting)**  

**IPF的信息理论观点** 

# 广义迭代标度(Generalized Iterative Scaling，GIS):介绍

# 广义迭代标度: 算法  

# IPF和GIS概述  

# 指数族

**PITMAN-KOOPMAN-DARMOIS定理** 

**指数族为什么如此频繁出现？** 

# 条件随机场(Conditional Random Fields,CRFs)  

**介绍**  

**推断与学习**

# 其他资源 

Jordan textbook, Ch. 11   
Koller textbook, Ch. 19.1-19.4  
Borman, The EM algorithm (A short tutorial)   
Variations on EM algorithm by Neal and Hinton   

参考：
[Lecture 6: Learning Partially Observed GM and the EM Algorithm](https://sailinglab.github.io/pgm-spring-2019/notes/lecture-06/)



