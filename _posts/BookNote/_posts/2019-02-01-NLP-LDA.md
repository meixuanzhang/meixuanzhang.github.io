---
layout: post
title: LDA(Latent Dirichlet Allocation)
date:   2019-01-01
categories: 
---

# 基础概念

**Beta(贝塔)函数和Gamma(伽玛)函数**  

欧拉积分是由瑞士数学家莱昂哈德·欧拉整理得出的两类特殊的含参变量的积分。由欧拉积分所定义的函数分别称为Beta函数和Gamma函数。——百度百科  

Gamma(伽玛)函数：  

$$\Gamma(s)=\int_{0}^{+\infty} x^{s-1}e^{-x}dx,(s>0)$$

Beta(贝塔)函数:  

$$B(p,q)=\int_{0}^{1} x^{p-1}(1-x)^{q-1}dx,(p>0,q>0)$$  

两者关系：  

$$B(p,q) = \frac{\Gamma(p)\Gamma(q)}{\Gamma(p+q)}$$

**Beta分布**

(二元)Beta分布的概率密度函数：  

$$
f(x;\alpha,\beta)= \frac{x^{\alpha-1}(1-x)^{\beta-1}} {\int_{0}^{1}\mu^{\alpha-1}(1-\mu)^{\beta-1}d\mu}\\
=\frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}\\
=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}x^{\alpha-1}(1-x)^{\beta-1}  
$$

**Dirichlet分布(多元Beta分布)**    

$$f(x_{1},...x_{K-1};\alpha_{1},...\alpha_{K})=\frac{1}{B(\mathbf{α})}\prod_{i=1}^{K}x_{i}^{\alpha_{i}-1}$$

自由度是K-1  

$$\sum_{i=1}^K x_{i}=1,x_{K}=1-\sum_{i=1}^{K-1}$$   

$$
B(\mathbf{α})=\frac{\prod_{i=1}^{K}\Gamma(\alpha_{i})} {\Gamma(\sum_{i=1}^K \alpha_{i})},\mathbf{α}=(\alpha_{1},...\alpha_{K})
$$

**先验概率&后验概率**  
**共轭分布&共轭先验**  
# LDA模型
**解决的问题**   

对文章进行归类，分为K类，获得每类文章的词频分布，确定每类文章关键词。

**Notation**  

K：主题数（类别数），常量
V：总词汇量，常量
M：文章总数，常量
$$N_{d=1..M}:$$每篇文章的词数，常量
$$N:$$所有文章词数和$$N=\sum_{d=1}^M N_{d}$$，常量
$$\theta_{i}:$$第i篇文章的类别分布，K维向量，向量元素和为1。  
例：假设K=3，类别是(娱乐、体育、科技)，文章i类别分布是(25%,25%,50%),元素和为1。每篇文章会有自己类别分布。  
$$\varphi_{k}:$$第k类文章词汇词频分布，V维向量，向量元素和为1。
$$$$
**模型推导过程**
目前已知每篇文章由哪些词构成。现假设这些文章词是由以下方式生成：   
1、假设每篇文章的类别分布(向量)，服从Dirichlet分布,从Dir分布中获得第i篇类别分布向量$$\theta_{i}$$
$$\theta_{i}~Dir(\mathbf{α}),i\in{1,...,M}$$
2、假设不同类别文章词汇词频分布(向量)，服从Dirichlet分布，从Dir分布中获得第i类文章词汇词频分布向量$$\varphi_{k}:$$  
$$$$

主题分布
主题中词的分布

LDA假设文档主题的先验分布是Dirichlet分布

LDA假设主题中词的先验分布是Dirichlet分布
