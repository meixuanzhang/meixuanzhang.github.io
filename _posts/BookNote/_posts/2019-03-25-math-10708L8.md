---
layout: post
title: 译Lecture 8 Causal Discovery and Inference
date:   2019-03-25
categories: ["Probabilistic Graphical Models"]
---  

因果发现的学习和推理算法。

因果关系意味着关联（或依赖），但关联并不意味着因果关系。例如，以巧克力消费量与诺贝尔奖获得者人数之比为例：

![_config.yml]({{ site.baseurl }}/images/10708/image154.png)  

从这个图中，我们可以看出它们是高度相关的。但是，如果我们想增加一个国家的诺贝尔奖获得者的数量，我们就需要多吃巧克力，这是荒谬的。这就是因果关系的概念。它们是相关的，但巧克力的消费并不是诺贝尔奖得主的原因。以下方程式从数学上捕捉了这种差异：

$$X$$和$$Y$$是相互依赖(dependent)的，当且仅当(存在)$$\exists x_1$$与$$ x_2 $$不同时:

$$P(Y \mid X=x_{1}) \text{ different than } P(Y \mid X=x_2)$$

$$X$$是$$Y$$的因(cause),当且仅当(存在)$$\exists x_1$$与$$ x_2 $$不同时:

$$P(Y \mid do(X=x_1)) \text{ different than } P(Y \mid X=x_2)$$

这个定义只需要一对不同的$$x_1，x_2$$有不同的$$Y$$条件分布。在$$X$$值的范围内，$$Y$$可能具有相同的条件分布，但是只要我们发现有一对的条件分布不同，则$$X$$和$$Y$$是相依的。因果关系也是如此。

因果关系的定义是循环的，如果我们不知道其他变量之间的因果关系，我们就不能定义$$X$$的干预(intervention)，从而无法找到$$$X$和$$Y$$的因果关系。所以为了定义一个因果关系，我们需要所有其他因果关系。

# 因果思维(Causal Thinking) 

## 辛普森悖论(Simpson’s Paradox) 

例1：假设有两种类型的病人，一种是小肾结石，另一种是大肾结石。有两种治疗方法可供选择，A和B。从数据中我们可以看出，如果我们分开考虑患者类别，治疗A在这两种情况下都有较高的治愈率。但如果我们不分开考虑患者类别，我们会发现B治疗有更高的治愈率83%（289/350）。那么，作为一名医生，你会建议病人采取哪种治疗方法？

![_config.yml]({{ site.baseurl }}/images/10708/image155.png)  

例2：我们绘制了不同年龄段人群胆固醇水平与运动量的关系图。对于每个年龄段的人来说，我们发现运动越多，胆固醇就越少。但是，如果我们不区分年龄组来研究，我们会看到相反的结果：你锻炼得越多，胆固醇含量就越高。

![_config.yml]({{ site.baseurl }}/images/10708/image156.png)  

在这两个例子中，我们比较的变量之间有一个共同的原因，由于这个共同原因，变量之间的关系可以是任意的。我们应该确定共因的值，然后看看我们要比较的变量之间的关系。


## 奇怪的依赖(Strange Dependence)

如果我们回溯到50年前，我们发现女大学生在智商测试中的平均得分高于男大学生。性别和智商是两个非常不同的变量，我们可以有把握地假设它们是独立的。但考虑到一个共同的原因，比如说上大学，现在他们变得依赖了。理解这一点的一个简单方法如下：如果我们以$$X$$和$$Y$$的和为条件，两个自变量$$X$$和$$Y$$变得相依。

![_config.yml]({{ site.baseurl }}/images/10708/image157.png) 

**v**

设置如下。有三扇门，其中一扇门后面有1000美元。如果我们选了那扇门，我们就能拿到奖金。所以我们做了初步的猜测，然后游戏节目主持人打开其中一扇空门，显示门后没有钱。我们应该坚持最初的选择还是换到另一扇门？
答案是改变我们的选择。如果我们改变选择，我们获胜的概率就变成2/3，而不是1/3。我们可以这样想,最初有三个选择，两个空门和一个奖金。如果我们总是改变选择，则如果最初选择了空门,我们将获得奖金，如果我们最初选择了带有奖金的门，我们将失败。所以要想赢，首先要选择概率为2/3的空门。所以如果我们总是改变选择，我们赢得奖金的几率是2/3。

## 因果模型

如果我们有因果模型，就很容易进行干预。我们只需要删除所有进入节点的边，然后对得到的图形结构进行推理。
另外，如果我们知道因果结构，我们可以将一些已知分布应用到新的场景中。这一思想被用于迁移学习。

## 预测

$$P(Y \mid X)$$意味$$X$$恰好取某个特定值时$$Y$$的概率。这可以从观测数据中发现。我们不需要任何图表或因果关系来找到这个值。

## 干预(Intervention) 

$$P(Y \mid do(X))$$意味$$X$$被设置为一个特定值，并且所有其他变量不变时，$$Y$$的概率是多少。为此，我们必须知道所有变量之间的因果关系。

## 反事实思考(Counterfactual Thinking)

这回答的问题，即鉴于我们实际上观察到$$X$$和$$Y$$，如果$$X$$为$$x$$，则将观察到事件$$Y = y$$的概率是多少。为此，我们再次需要通过结构方程模型建立因果关系。

# 因果关系认定  

## Causal DAGs   

因果DAG中的每条边对应于节点之间的直接因果影响，并且是非对称的。设$$P_x(V)$$为干预$$do(X=x)$$产生的分布。DAG为因果DAG如果满足

+ $$P_x(V)$$是相对于G的Markov，根据G的Markov性质(每个节点给定其父节点的概率的乘积)，这个分布仍然是可分解的

+ 对于$$ V_i \in X$$,$$ P_x(V_i = v_i) = 1 $$,$$ v_i $$与$$X=x$$一致。这是因为我们对$$X$$进行了干预，并将其设置为$$x$$。因此我们绝对确定地知道这些变量。

+ $$P_x(V_i \mid PA_i) = P(V_i \mid PA_i)$$ 对于所有 $$V_i \notin X$$ ,$$ PA_i $$ 表示为$$ V_i $$的父节点。这意味着未包括在干预中的所有节点的条件分布干预之前和之后保持相同。我们可以通过图形方式看到这一点，因为进行干预时，我们只需删除所有进入执行干预节点的边。。 因此其他节点保持不变（以父节点而言）

## 随机对照试验(Randomized Control Experiments)

## 肾结石实验(Kidney Stone Experiment)

## 因果关系可识别性(因果关系可识别性)  

## 因果发现


参考：
[Lecture 6: Learning Partially Observed GM and the EM Algorithm](https://sailinglab.github.io/pgm-spring-2019/notes/lecture-07/)



