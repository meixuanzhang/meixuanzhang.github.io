---
layout: post
title: 译Lecture 8 Causal Discovery and Inference
date:   2019-03-25
categories: ["Probabilistic Graphical Models"]
---  

因果发现的学习和推理算法。

因果关系意味着关联（或依赖），但关联并不意味着因果关系。例如，以巧克力消费量与诺贝尔奖获得者人数之比为例：

![_config.yml]({{ site.baseurl }}/images/10708/image154.png)  

从这个图中，我们可以看出它们是高度相关的。但是，如果我们想增加一个国家的诺贝尔奖获得者的数量，我们就需要多吃巧克力，这是荒谬的。这就是因果关系的概念。它们是相关的，但巧克力的消费并不是诺贝尔奖得主的原因。以下方程式从数学上捕捉了这种差异：

$$X$$和$$Y$$是相互依赖(dependent)的，当且仅当(存在)$$\exists x_1$$与$$ x_2 $$不同时:

$$P(Y \mid X=x_{1}) \text{ different than } P(Y \mid X=x_2)$$

$$X$$是$$Y$$的因(cause),当且仅当(存在)$$\exists x_1$$与$$ x_2 $$不同时:

$$P(Y \mid do(X=x_1)) \text{ different than } P(Y \mid X=x_2)$$

这个定义只需要一对不同的$$x_1，x_2$$有不同的$$Y$$条件分布。在$$X$$值的范围内，$$Y$$可能具有相同的条件分布，但是只要我们发现有一对的条件分布不同，则$$X$$和$$Y$$是相依的。因果关系也是如此。

因果关系的定义是循环的，如果我们不知道其他变量之间的因果关系，我们就不能定义$$X$$的干预(intervention)，从而无法找到$$$X$和$$Y$$的因果关系。所以为了定义一个因果关系，我们需要所有其他因果关系。

# 因果思维(Causal Thinking) 

## 辛普森悖论(Simpson’s Paradox) 

例1：假设有两种类型的病人，一种是小肾结石，另一种是大肾结石。有两种治疗方法可供选择，A和B。从数据中我们可以看出，如果我们分开考虑患者类别，治疗A在这两种情况下都有较高的治愈率。但如果我们不分开考虑患者类别，我们会发现B治疗有更高的治愈率83%（289/350）。那么，作为一名医生，你会建议病人采取哪种治疗方法？

![_config.yml]({{ site.baseurl }}/images/10708/image155.png)  

例2：我们绘制了不同年龄段人群胆固醇水平与运动量的关系图。对于每个年龄段的人来说，我们发现运动越多，胆固醇就越少。但是，如果我们不区分年龄组来研究，我们会看到相反的结果：你锻炼得越多，胆固醇含量就越高。

![_config.yml]({{ site.baseurl }}/images/10708/image156.png)  

在这两个例子中，我们比较的变量之间有一个共同的原因，由于这个共同原因，变量之间的关系可以是任意的。我们应该确定共因的值，然后看看我们要比较的变量之间的关系。


## 奇怪的依赖(Strange Dependence)

如果我们回溯到50年前，我们发现女大学生在智商测试中的平均得分高于男大学生。性别和智商是两个非常不同的变量，我们可以有把握地假设它们是独立的。但考虑到一个共同的原因，比如说上大学，现在他们变得依赖了。理解这一点的一个简单方法如下：如果我们以$$X$$和$$Y$$的和为条件，两个自变量$$X$$和$$Y$$变得相依。

![_config.yml]({{ site.baseurl }}/images/10708/image157.png) 

**v**

设置如下。有三扇门，其中一扇门后面有1000美元。如果我们选了那扇门，我们就能拿到奖金。所以我们做了初步的猜测，然后游戏节目主持人打开其中一扇空门，显示门后没有钱。我们应该坚持最初的选择还是换到另一扇门？
答案是改变我们的选择。如果我们改变选择，我们获胜的概率就变成2/3，而不是1/3。我们可以这样想,最初有三个选择，两个空门和一个奖金。如果我们总是改变选择，则如果最初选择了空门,我们将获得奖金，如果我们最初选择了带有奖金的门，我们将失败。所以要想赢，首先要选择概率为2/3的空门。所以如果我们总是改变选择，我们赢得奖金的几率是2/3。

## 因果模型

如果我们有因果模型，就很容易进行干预。我们只需要删除所有进入节点的边，然后对得到的图形结构进行推理。
另外，如果我们知道因果结构，我们可以将一些已知分布应用到新的场景中。这一思想被用于迁移学习。

## 预测

$$P(Y \mid X)$$意味$$X$$恰好取某个特定值时$$Y$$的概率。这可以从观测数据中发现。我们不需要任何图表或因果关系来找到这个值。

## 干预(Intervention) 

$$P(Y \mid do(X))$$意味$$X$$被设置为一个特定值，并且所有其他变量不变时，$$Y$$的概率是多少。为此，我们必须知道所有变量之间的因果关系。

## 反事实思考(Counterfactual Thinking)

这回答的问题，即鉴于我们实际上观察到$$X$$和$$Y$$，如果$$X$$为$$x$$，则将观察到事件$$Y = y$$的概率是多少。为此，我们再次需要通过结构方程模型建立因果关系。

# 因果关系认定  

## Causal DAGs   

因果DAG中的每条边对应于节点之间的直接因果影响，并且是非对称的。设$$P_x(V)$$为干预$$do(X=x)$$产生的分布。DAG为因果DAG如果满足

+ $$P_x(V)$$是相对于G的Markov，根据G的Markov性质(每个节点给定其父节点的概率的乘积)，这个分布仍然是可分解的

+ 对于$$ V_i \in X$$,$$ P_x(V_i = v_i) = 1 $$,$$ v_i $$与$$X=x$$一致。这是因为我们对$$X$$进行了干预，并将其设置为$$x$$。因此我们绝对确定地知道这些变量。

+ $$P_x(V_i \mid PA_i) = P(V_i \mid PA_i)$$ 对于所有 $$V_i \notin X$$ ,$$ PA_i $$ 表示为$$ V_i $$的父节点。这意味着未包括在干预中的所有节点的条件分布干预之前和之后保持相同。我们可以通过图形方式看到这一点，因为进行干预时，我们只需删除所有进入执行干预节点的边。因此其他节点保持不变（以父节点而言）

## 随机对照试验(Randomized Control Experiments)

我们改变一个控制变量，观察结果变量(outcome variable)的变化。影响结果变量的所有其他变量要么是固定的，要么是随机变化的。所以现在在结果变量中观察到的任何变化都是由于控制变量的变化。
它的缺点是昂贵，而且在许多情况下是不可能做到的。结果变量可以依赖于许多其他变量。因此，要找到一个因果关系，我们需要大量的数据，我们需要确保其他变量在实验中是固定的或随机变化的，这是一项非常困难的任务。

## 肾结石实验(Kidney Stone Experiment)

让我们回顾一下肾结石治疗的例子。 令R =恢复，T =处理，S =结石大小，则

$$P(R \mid T) = \sum_S P(R \mid S,T)P(S \mid T)$$

$$P(R \mid do(T)) = \sum_S P(R \mid S,T)P(S)$$

请注意，在进行干预时，我们切断了所有进入治疗节点的边。所以，现在S和T是独立的。

## 因果关系可识别性(因果关系可识别性)  

统计模型的一个方面是可识别的，如果它不能在观测变量的分布没有一些变化的情况下改变。因此，如果我们可以将变量表达为观察变量分布的函数，那么可以说变量是可识别的。 因此，当且仅当我们可以根据观察变量(observed variables)的分布来表示$$P(Y\mid do(X))$$时，因果效应才能确定。 即如果

$$ P_{M1}(Y \mid do(X)) = P_{M2}(Y \mid do(X)) $$,对于具有dame图和相同观测变量分布的M1和M2模型（未观测/潜在变量分布可以改变）

如果我们只有两个随机变量$$X$4和$$Y$$(都是观察到的)，其中$$X$$是$$Y$4的因，而没有混杂因子(confounder)。所以$$P(Y \mid do(X)) = P(Y \mid X)$$，我们知道这是可识别的，因为改变$$P(Y \mid X)$$，我们必须改变$$P(X,Y)$的分布。

但是，现在让我们假设我们有一个混杂因子$$C$4，这是$$X$$和$$Y$$的共因，这是没有观察到的。现在，我们可以改变$$C$$的分布，使$$P(X,Y)$$不变，但得到不同的$$P(Y \mid do(X))$$，$$P(Y \mid do(X))$$也可以写成$$P(y \mid \hat{x})$$

**BACK-DOOR CRITERION**

**FRONT-DOOR CRITERION**  

**UNIFICATION**

**PROPENSITY SCORE**



## 因果发现

**PC ALGORITHM**


参考：
[Lecture 6: Learning Partially Observed GM and the EM Algorithm](https://sailinglab.github.io/pgm-spring-2019/notes/lecture-07/)



