---
layout: post
title: 译Lecture 5 Parameter Estimation in Fully Observed Bayesian Networks
date:   2019-03-25
categories: ["Probabilistic Graphical Models"]
---  

介绍全观测贝叶斯网络(fully observed Bayesian Networks)参数估计 。  

# 介绍(Introduction)  

上一课，我们介绍了两种主要的图模型任务类型：推理(Inference)和学习(Learning)，并且我们主要讨论了推理(Inference)。 在本讲座中，我们将开始介绍学习(Learning)任务，并探索可用于全观测贝叶斯网络学习任务的技术。    

# 学习图模型(Learning Graphical Models)   

在开始之前，最好先了解一下什么是学习(Learning)以及实现的目标是什么。

## 目标(The goal)  

目标：给定一组独立样本(随机变量的赋值),找到最佳（或最有可能）贝叶斯网络(DAG和CPD)。 

如下图所示，我们得到了一组独立样本（二进制随机变量的赋值）。假设它是一个DAG，我们将学习节点之间的有向链接(因果关系),这个过程称为结构学习(Structural Learning)。学习条件概率是另一个被称为参数学习(Parameter learning)的任务。


![_config.yml]({{ site.baseurl }}/images/10708/image79.png)   

## 总览(Overview)

如下所示，我们对以下几个学习场景感兴趣：  

1、全观测的图模型(Completely observed GMs)   

+ 1.1 有向(directed)  
+ 1.2 无向(undirected)  

2、部分或未观察到的图模型(Partially or unobserved GMs)  

+ 1.1 有向(directed)  
+ 1.2 无向(undirected)（一个开放的研究课题）   

这里还列出了一些有用的估算原理：  

最大似然估计(MLE):Maximal likelihood estimation
贝叶斯估计:Bayesian estimation
最大条件似然: Maximal conditional likelihood
最大“边际”：Maximal “Margin”
最大熵：Maximum entropy  

我们使用learning作为估计参数这一过程的名字，在某些情况下，使用数据来估计网络的拓扑结构。

# 参数学习(Parameter Learning)  






参考：
[Lecture 4: Exact Inference](https://sailinglab.github.io/pgm-spring-2019/notes/lecture-04/)



