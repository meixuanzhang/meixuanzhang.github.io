---
layout: post
title: PGM :Representation 3 
date:   2019-03-25
categories: ["Probabilistic Graphical Models"]
---

# 一、Markov Network Fundamentals  

概率无向图模型（Probabilistic undirected graphical model）又称马尔可夫随机场（Markov random field）或马尔可夫网  

## 1、Pairwise Markov Network   

图中A,B,C,D代表4个学生，这里的随机变量是对材料的误解，有误解代表是1，没有误解代表是0，这是马尔可夫网络，没有明确的方向，相互之间存在影响   
基于直觉，我们知道两个同学在一起学习， 他们相互之间会有所影响   
$$\phi$$是infinity functions or compatibility functions.值范围不是0到1

![_config.yml]({{ site.baseurl }}/images/3PGM/image1.png)   

Z是partition function，用于标准化  

![_config.yml]({{ site.baseurl }}/images/3PGM/image2.png)    

B同意A，C同意B，D不同意C，D同意A，这里不能构成循环，因为C同意A，但D不同意C，最后D同意A，这是矛盾的，循环应该断开   
$$\phi_1(A,B)$$分配之间的差异大于其他组，是比较弱的因子，可以将AB边断开  

![_config.yml]({{ site.baseurl }}/images/3PGM/image3.png)   

![_config.yml]({{ site.baseurl }}/images/3PGM/image4.png)  

**Pairwise Markov Network**

![_config.yml]({{ site.baseurl }}/images/3PGM/image5.png)

## 2、General Gibbs Distribution  

n个随机变量的概率分布，参数有$$d^n$$    
Not every distribution can be represented as a pairwise Markov network   

![_config.yml]({{ site.baseurl }}/images/3PGM/image6.png)

![_config.yml]({{ site.baseurl }}/images/3PGM/image7.png)

**Gibbs Distribution**  

无向图模型中，通过$$\Phi$$因子分解表示出的$$P_{\Phi}$$，则$$P_{\Phi}$$是Gibbs Distribution

![_config.yml]({{ site.baseurl }}/images/3PGM/image8.png)  

![_config.yml]({{ site.baseurl }}/images/3PGM/image9.png) 

**Induced Markov Network**  

节点在同一个factor里，则任意节点之间在图中都有边相连，如果图描述出factor展示关系，则图的P可以通过factor进行因子分解表示

![_config.yml]({{ site.baseurl }}/images/3PGM/image10.png)  

![_config.yml]({{ site.baseurl }}/images/3PGM/image11.png)  

**Factorization**   

P通过马尔可夫网络进行因子分解条件：    

![_config.yml]({{ site.baseurl }}/images/3PGM/image12.png)  
  

**Flow of Influence**   

两种factorization描述了一样图结构  
举个例子ADC，A要通过D才能影响C，节点在同一个factor里能相连，没有直接相连说明不在一个factor A和C不在一个factor,第一条式子通过$$\phi_{1},\phi_{2}$$ 表达了这种关系，第二条则通过$$\phi_{3},\phi_{4}$$
![_config.yml]({{ site.baseurl }}/images/3PGM/image13.png)

**Active Trails的条件**

![_config.yml]({{ site.baseurl }}/images/3PGM/image14.png)  

**Summary**    

Gibbs distribution 可以通过factors描述分布    
Induced Markov network 将在同一个factor的节点两两相连  
Markov network 结构不能定义P因子分解的方式  
active trails只取决于图结构  

![_config.yml]({{ site.baseurl }}/images/3PGM/image15.png)  

## 3、Conditional Random Fields  

![_config.yml]({{ site.baseurl }}/images/3PGM/image16.png)  


贝叶斯公式： $$P(Y\mid X)=\frac{P(X\mid Y)P(Y)}{P(X)}$$    
朴素贝叶斯假设在条件Y下X变量之间是独立的$$P(X\mid Y)=P(X_{1}\mid Y)..P(X_{k}\mid Y)$$，但变量X之间关联非常强，不满足假设  
需要能计算$$P(Y\mid X)$$，同时不需要假设条件Y下X变量之间是独立的

![_config.yml]({{ site.baseurl }}/images/3PGM/image17.png)   

![_config.yml]({{ site.baseurl }}/images/3PGM/image18.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image19.png)

**CRFs and Logistic Model** 

the logistic model is a very simple CRF.

![_config.yml]({{ site.baseurl }}/images/3PGM/image20.png)  

**Summary**  

![_config.yml]({{ site.baseurl }}/images/3PGM/image21.png)

# 二、Independencies in Markov Networks and Bayesian Network
## Independencied in Markov Networks  

![_config.yml]({{ site.baseurl }}/images/3PGM/image22.png)

![_config.yml]({{ site.baseurl }}/images/3PGM/image23.png)

![_config.yml]({{ site.baseurl }}/images/3PGM/image24.png)

![_config.yml]({{ site.baseurl }}/images/3PGM/image25.png)

![_config.yml]({{ site.baseurl }}/images/3PGM/image26.png)

## I-maps and perfect maps   
 
![_config.yml]({{ site.baseurl }}/images/3PGM/image27.png)  

![_config.yml]({{ site.baseurl }}/images/3PGM/image28.png)

如果图g是独立关系集I(P)的一个I-map(图g中描述的独立关系属于独立关系集I(P)),并且从g中移除一条甚至是单边的边都会使其不再是I-map(移除边后新增的独立关系不属于I(P)) ，那么图g是I的最小的I-map  

![_config.yml]({{ site.baseurl }}/images/3PGM/image29.png) 

**Perfect Map**  

![_config.yml]({{ site.baseurl }}/images/3PGM/image30.png)

左图马尔可夫网络描述的P在贝叶斯网络上没有perfect map


![_config.yml]({{ site.baseurl }}/images/3PGM/image31.png)

图没有描述出$$X_{1}\perp X_{2},X_{1}\perp Y,X_{2}\perp Y$$不是perfect map  


![_config.yml]({{ site.baseurl }}/images/3PGM/image32.png)

左边贝叶斯网络描述的P，右图是马尔可夫网络是P的I-map,但无法找到P的perfect 马尔可夫map   


![_config.yml]({{ site.baseurl }}/images/3PGM/image33.png)

不同的图可以描述出一样的独立假设，可以描述出有相同假设的分布，
![_config.yml]({{ site.baseurl }}/images/3PGM/image34.png)  

![_config.yml]({{ site.baseurl }}/images/3PGM/image35.png)  

![_config.yml]({{ site.baseurl }}/images/3PGM/image36.png) 

将BN转换成MN，BN的V结构将失去原有的独立性  
将MN转换成BN，要加上三角边(如perfect Map图片所示)   

![_config.yml]({{ site.baseurl }}/images/3PGM/image37.png) 

# 三、Local Structure in Markov Network   

## 1、Log-Linear Models  

factors$$\Phi=\{\phi_{1}(D_{1}),....,\phi_{k}(D_{k})\}$$

$$
P_{\Phi}(X_{1},...X_{n})=\frac{1}{Z}\tilde{P}_{\Phi}(X_{1},...X_{n})\\

\tilde{P}_{\Phi}(X_{1},...X_{n})=\phi_{1}(D_{1})x\phi_{2}(D_{2})x...x\phi_{m}(D_{m})\\

Z=\sum_{X_{1},...X_{n}}\tilde{P}_{\Phi}(X_{1},...X_{n})
$$



![_config.yml]({{ site.baseurl }}/images/3PGM/image38.png)  

![_config.yml]({{ site.baseurl }}/images/3PGM/image39.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image40.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image41.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image42.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image43.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image44.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image45.png) 

![_config.yml]({{ site.baseurl }}/images/3PGM/image46.png) 

truncated linear penalty  

So here we have a set of variables X that correspond to the noisy pixels. And we'd let, we have a set of variables y that correspond to the clean pixels 
we'd like to have a probabilistic model that relates X and X and Y
