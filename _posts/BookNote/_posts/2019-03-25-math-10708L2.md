---
layout: post
title: 译Lecture 2 Bayesian Networks
date:   2019-03-25
categories: ["Probabilistic Graphical Models"]
---  

动机：通过一些随机变量表示联合分布在计算成本上是昂贵的，所以我们需要方法来紧凑地表示联合分布。  

# 两种图模型(Graphical Models)  


**有向图(Directed Graphs)** (Bayesian Networks)  

一个非非环形图$$g$$,由一组节点$$V$$和一组有方向的边$$\varepsilon$$组成，边连接的两个节点具有因果关系(causality relationship),图中的节点代表一组随机变量$$X_{1},X_{2}...X_{N}$$,节点和随机变量之间存在一对一的映射。 

![_config.yml]({{ site.baseurl }}/images/10708/image14.png)  
 

上述有向图的联合概率可以写成：

$$P(X_{1},...,X_{8})=P(X_{1})P(X_{2})P(X_{3}\mid X_{1})P(X_{4}\mid X_{2})P(X_{5}\mid X_{2})P(X_{6}\mid X_{3},X_{4})P(X_{7}\mid X_{6})P(X_{8}\mid X_{5},X_{6})$$   


**无向图(Undirected Graphs)** (Markov Random Fields)  

![_config.yml]({{ site.baseurl }}/images/10708/image15.png)   

无向图包含通过无方向边连接的节点。  


# 标记(Notation)   

**变量(Variable)**: 大写英文字母,下标代表所处维度(i),上标表示索引(j)如：$$ V_{i}^j $$    
**变量值(Values of variables)**: 小写字母表示它是某个随机变量的“观察值”如：$$v_{i}^j$$   
**随机变量(Random variable)**: 具有随机性的变量，根据不同的观察结果之间会发生变化。   
**随机向量(Random vector)**: 大写加粗字母(维度 1 X n).   
**随机矩阵(Random matrix)**:大写加粗字母(维度 n X n).   
**参数(Parameters)**: 希腊字符,可以认为是随机变量。   

# The Dishonest Casino(不诚实的赌场)  

设X是序列的随机变量，随机变量序列为(random sequence),$$X_{1},..,X_{T}$$。$$X_{t}$$是赌场骰子结果,$$X \in (1,2,3,4,5,6)$$，$$Y$$是随机变量的解析,$$Y_{t}$$表示骰子是公正或有偏差的，$$Y\in (0,1)$$。有偏差的骰子，每个点数发生概率分布如下：  

![_config.yml]({{ site.baseurl }}/images/10708/image16.png)    

我们可能想问的一些问题是：  

**评估(Evaluation):** 给定赌场模型下，序列发生的可能性有多大？  

**解码(Decoding):** 序列中哪些部分是用公平骰子生成的，哪些部分是用有偏差骰子生成的？ 

**学习(Learning):** How “loaded” is the loaded dice? How “fair” is the fair dice?，赌场玩家将公平骰子换成有偏差骰子频率？

Loaded dice:A loaded, weighted, cheat, or crooked die is one that has been tampered with so that it will land with a specific side facing upwards more or less often than a fair die would. 

我们可以对赌场问题进行建模的一种方法是使用隐马尔可夫模型，其中$$X_{t}$$是观测变量(observed variables)，$$Y_{t}$$是隐藏变量(hidden variables)：  

![_config.yml]({{ site.baseurl }}/images/10708/image17.png)    

所有隐藏变量均具有Markov属性，即在给定当前条件下过去有条件地独立于未来：    

$$Y_{t-1} \bot \{Y_{t+1},...,Y_{T}\}\mid Y_{t}$$   

此属性在图的拓扑中也显式突出显示。  

此外，根据我们的HMM序列，我们可以计算可能性，如下所示：  

$$P(\mathbf{X},\mathbf{Y})=$$





参考：
[Lecture 2: Bayesian Networks](https://sailinglab.github.io/pgm-spring-2019/notes/lecture-02/)